{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item features shape: (10, 16)\n",
      "User features shape: (5000, 128)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the item data\n",
    "item_data_path = 'data/sushi3-2016/sushi3.idata'\n",
    "item_columns = ['item_id', 'name', 'style', 'major_group', 'minor_group', 'heaviness', 'consumption_frequency', 'normalized_price', 'sell_frequency']\n",
    "item_df = pd.read_csv(item_data_path, sep='\\t', header=None, names=item_columns)\n",
    "\n",
    "# Filter the item data to include only the 10 items used in the paper\n",
    "item_set_A_ids = [0, 1, 2, 3, 4, 6, 7, 8, 26, 29]\n",
    "#item_set_A_ids=[i for i in range(100)]\n",
    "item_set_A_df = item_df[item_df['item_id'].isin(item_set_A_ids)]\n",
    "\n",
    "# Preprocess the item features\n",
    "categorical_features = ['style', 'major_group', 'minor_group']\n",
    "numerical_features = ['heaviness', 'consumption_frequency', 'normalized_price', 'sell_frequency']\n",
    "\n",
    "# Convert categorical features to strings to ensure get_dummies works correctly\n",
    "\n",
    "item_features = pd.get_dummies(item_set_A_df[categorical_features].astype(str))\n",
    "item_features = pd.concat([item_features, item_set_A_df[numerical_features]], axis=1)\n",
    "\n",
    "# Display the preprocessed item features\n",
    "print(\"Item features shape:\", item_features.shape)\n",
    "\n",
    "# Load the user data\n",
    "user_data_path = 'data/sushi3-2016/sushi3.udata'\n",
    "user_columns = ['user_id', 'gender', 'age', 'total_time', 'prefecture_longest', 'region_longest', 'east_west_longest', 'prefecture_current', 'region_current', 'east_west_current', 'prefecture_diff']\n",
    "user_df = pd.read_csv(user_data_path, sep='\\t', header=None, names=user_columns)\n",
    "\n",
    "# Preprocess the user features\n",
    "categorical_features_user = ['gender', 'age', 'prefecture_longest', 'region_longest', 'east_west_longest', 'prefecture_current', 'region_current', 'east_west_current']\n",
    "\n",
    "# Convert categorical features to strings to ensure get_dummies works correctly\n",
    "user_df[categorical_features_user] = user_df[categorical_features_user].astype(str)\n",
    "\n",
    "user_features = pd.get_dummies(user_df[categorical_features_user])\n",
    "\n",
    "# Display the preprocessed user features\n",
    "print(\"User features shape:\", user_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando o arquivo de preferencias e removendo as duas primeiras colunas de metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and parse the preference order data manually\n",
    "preference_data_path = 'data/sushi3-2016/sushi3a.5000.10.order'\n",
    "with open(preference_data_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Remove the first row which contains metadata\n",
    "lines = lines[1:]\n",
    "\n",
    "# Split each line into a list of preferences\n",
    "preference_data = [line.strip().split() for line in lines]\n",
    "\n",
    "# Convert to a DataFrame\n",
    "preference_df = pd.DataFrame(preference_data)\n",
    "\n",
    "# Convert all values to integers\n",
    "preference_df = preference_df.astype(int)\n",
    "\n",
    "# Rename columns for clarity\n",
    "preference_df.columns = [f'pref_{i}' for i in range(preference_df.shape[1])]\n",
    "\n",
    "# Display the processed preference data\n",
    "\n",
    "# Remove the first two columns if they contain metadata\n",
    "preference_df = preference_df.drop(columns=['pref_0', 'pref_1'])\n",
    "\n",
    "# Rename columns for clarity\n",
    "preference_df.columns = [f'pref_{i}' for i in range(preference_df.shape[1])]\n",
    "\n",
    "# Display the cleaned preference data\n",
    "print(preference_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_9128\\2437098629.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  item_i = preferences[i]\n",
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_9128\\2437098629.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  item_j = preferences[j]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_i  item_j\n",
      "0        0       5       0\n",
      "1        0       5       3\n",
      "2        0       5       4\n",
      "3        0       5       6\n",
      "4        0       5       9\n",
      "(225000, 3)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_pairwise(preference_df):\n",
    "    pairwise_data = []\n",
    "    for user_id, preferences in preference_df.iterrows():\n",
    "        for i in range(len(preferences)):\n",
    "            for j in range(i + 1, len(preferences)):\n",
    "                item_i = preferences[i]\n",
    "                item_j = preferences[j]\n",
    "                pairwise_data.append([user_id, item_i, item_j])\n",
    "    pairwise_df = pd.DataFrame(pairwise_data, columns=['user_id', 'item_i', 'item_j'])\n",
    "    return pairwise_df\n",
    "\n",
    "# Convert the preference data to pairwise format\n",
    "pairwise_df = convert_to_pairwise(preference_df)\n",
    "\n",
    "# Display the processed pairwise preference data\n",
    "print(pairwise_df.head())\n",
    "print(pairwise_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_i</th>\n",
       "      <th>item_j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_i  item_j\n",
       "34          0       6       2\n",
       "1           0       5       3\n",
       "31          0       6       8\n",
       "22          0       3       7\n",
       "23          0       3       2\n",
       "...       ...     ...     ...\n",
       "4484       99       3       5\n",
       "4496       99       9       5\n",
       "4457       99       7       3\n",
       "4464       99       2       1\n",
       "4491       99       4       6\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now subsample the pairwise data taking 5 pairs for each of the first 50 users\n",
    "pairwise_df = pairwise_df[pairwise_df['user_id'] < 100]\n",
    "pairwise_df = pairwise_df.sample(10*100, random_state=0)\n",
    "\n",
    "#order df by user_id\n",
    "pairwise_df = pairwise_df.sort_values('user_id')\n",
    "pairwise_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preference(user_idx, prod_1_idx, prod_2_idx):\n",
    "    user_pref = preference_df.loc[user_idx]\n",
    "\n",
    "    for i in range(len(user_pref)):\n",
    "        if user_pref.iloc[i] == prod_1_idx:\n",
    "            return 1\n",
    "        if user_pref.iloc[i] == prod_2_idx:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "class GPPrefenceElicitation:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, user_features, item_features, preference_data, max_iter=100):\n",
    "        self.user_features = user_features\n",
    "        self.item_features = item_features\n",
    "        self.preference_data = preference_data\n",
    "        self.n_users = user_features.shape[0]\n",
    "        self.n_items = item_features.shape[0]\n",
    "        self.max_iter=max_iter\n",
    "        self.maximum_hyperparameters(max_iter=self.max_iter)\n",
    "        user_covariance = self.kernel_covariance_matrix(user_features, user_features, self.sv_t, self.ls_t)\n",
    "        item_covariance = self.kernel_covariance_matrix(item_features, item_features, self.sv_k, self.ls_k)\n",
    "        self.covariance_matrix = torch.kron(user_covariance, item_covariance)\n",
    "        self.precision_matrix = torch.linalg.inv(self.covariance_matrix+torch.eye(self.n_users*self.n_items)*0.000001)\n",
    "    \n",
    "    def grad_log_p_D_given_f(self, f):\n",
    "        f = torch.tensor(f, dtype=torch.float32)\n",
    "        grad = torch.zeros_like(f, dtype=torch.float32)\n",
    "        \n",
    "        for preference in self.preference_data:\n",
    "            t, k_1, k_2 = preference\n",
    "            index_1 = t * self.n_items + k_1\n",
    "            index_2 = t * self.n_items + k_2\n",
    "            z = (f[index_1] - f[index_2]) / self.noise_sd\n",
    "            phi_val = scipy.stats.norm.pdf(z)\n",
    "            Phi_val = scipy.stats.norm.cdf(z)\n",
    "            ratio = phi_val / (Phi_val * self.noise_sd)\n",
    "            grad[index_1] += ratio\n",
    "            grad[index_2] -= ratio\n",
    "        \n",
    "        return grad\n",
    "        \n",
    "    def hessian_log_p_D_given_f(self, f):\n",
    "        hessian = torch.zeros((f.shape[0], f.shape[0]), dtype=torch.float32)\n",
    "        \n",
    "        for preference in self.preference_data:\n",
    "            t, k_1, k_2 = preference\n",
    "            index_1 = t * self.n_items + k_1\n",
    "            index_2 = t * self.n_items + k_2\n",
    "            z = (f[index_1] - f[index_2]) / self.noise_sd\n",
    "            phi_val = scipy.stats.norm.pdf(z)\n",
    "            Phi_val = scipy.stats.norm.cdf(z)\n",
    "            ratio = phi_val / (Phi_val * self.noise_sd)\n",
    "            \n",
    "            second_derivative = (z * ratio + ratio**2) / (self.noise_sd ** 2)\n",
    "            hessian[index_1, index_1] -= second_derivative\n",
    "            hessian[index_2, index_2] -= second_derivative\n",
    "            hessian[index_1, index_2] += second_derivative\n",
    "            hessian[index_2, index_1] += second_derivative\n",
    "        \n",
    "        return hessian\n",
    "    \n",
    "    def maximum_a_posteriori(self, initial_f, max_iter=100):\n",
    "        f = torch.tensor(initial_f, dtype=torch.float32)\n",
    "        for i in range(max_iter):\n",
    "            hessian = self.hessian_log_p_D_given_f(f)\n",
    "            precision_matrix_post = hessian + torch.tensor(self.precision_matrix, dtype=torch.float32)\n",
    "            grad = self.grad_log_p_D_given_f(f)\n",
    "            hessian_mult_f = hessian @ f\n",
    "            f = torch.linalg.solve(precision_matrix_post, grad + hessian_mult_f)\n",
    "        \n",
    "        return f\n",
    "    \n",
    "    def se_kernel(self, x, y, sv, ls):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        return sv * torch.exp(-0.5 * torch.linalg.norm(x - y) ** 2 / ls ** 2)\n",
    "    \n",
    "    def kernel_covariance_matrix(self, x, y, sv, ls):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        n_x = x.shape[0]\n",
    "        n_y = y.shape[0]\n",
    "        covariance_matrix = torch.zeros((n_x, n_y), dtype=torch.float32)\n",
    "        \n",
    "        for i in range(n_x):\n",
    "            for j in range(n_y):\n",
    "                covariance_matrix[i, j] = self.se_kernel(x[i], y[j], sv, ls)\n",
    "        \n",
    "        return covariance_matrix\n",
    "\n",
    "    def maximum_hyperparameters(self, init_sv_t=1.0, init_ls_t=1.0, init_sv_k=1.0, init_ls_k=1.0, init_noise_sd=0.1, max_iter=100):\n",
    "        sv_t = torch.tensor(init_sv_t, requires_grad=True, dtype=torch.float32)\n",
    "        ls_t = torch.tensor(init_ls_t, requires_grad=True, dtype=torch.float32)\n",
    "        sv_k = torch.tensor(init_sv_k, requires_grad=True, dtype=torch.float32)\n",
    "        ls_k = torch.tensor(init_ls_k, requires_grad=True, dtype=torch.float32)\n",
    "        self.noise_sd = torch.tensor(init_noise_sd, requires_grad=True, dtype=torch.float32)\n",
    "        optimizer = torch.optim.Adam([sv_t, ls_t, sv_k, ls_k, self.noise_sd])\n",
    "        identity = torch.eye(self.n_users * self.n_items, dtype=torch.float32)\n",
    "        for i in range(max_iter):\n",
    "            optimizer.zero_grad()\n",
    "            user_covariance = self.kernel_covariance_matrix(self.user_features, self.user_features, sv_t, ls_t)\n",
    "            item_covariance = self.kernel_covariance_matrix(self.item_features, self.item_features, sv_k, ls_k)\n",
    "            self.covariance_matrix = torch.kron(user_covariance, item_covariance)\n",
    "            self.precision_matrix = torch.inverse(self.covariance_matrix + torch.eye(self.n_users * self.n_items, dtype=torch.float32) * 0.000001)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                f = self.maximum_a_posteriori(np.zeros(self.n_users * self.n_items), max_iter=self.max_iter)\n",
    "                hessian = self.hessian_log_p_D_given_f(f)\n",
    "                grad = self.grad_log_p_D_given_f(f)\n",
    "            \n",
    "            f = f.reshape(1, -1)\n",
    "            sum_log_cdf = 0\n",
    "            for preference in self.preference_data:\n",
    "                t, k_1, k_2 = preference\n",
    "                index_1 = t * self.n_items + k_1\n",
    "                index_2 = t * self.n_items + k_2\n",
    "                sum_log_cdf += torch.log(torch.tensor(scipy.stats.norm.cdf((f[0, index_1] - f[0, index_2]) / self.noise_sd.detach().numpy()), dtype=torch.float32))\n",
    "            \n",
    "            loss = 0.5 * torch.logdet(self.covariance_matrix @ hessian + identity) + 0.5 * f @ self.precision_matrix @ f.T - sum_log_cdf\n",
    "            loss = loss.sum()  # Ensure the loss is a scalar\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        self.sv_t = sv_t.item()\n",
    "        self.ls_t = ls_t.item()\n",
    "        self.sv_k = sv_k.item()\n",
    "        self.ls_k = ls_k.item()\n",
    "        self.noise_sd = self.noise_sd.item()\n",
    "    \n",
    "    def predictive_mean_and_variance(self, user_features, item_features):\n",
    "        user_covariance = self.kernel_covariance_matrix(user_features, self.user_features, self.sv_t, self.ls_t)\n",
    "        item_covariance = self.kernel_covariance_matrix(item_features, self.item_features, self.sv_k, self.ls_k)\n",
    "        covariance_matrix = torch.kron(user_covariance, item_covariance)\n",
    "        predictive_mean = item_covariance @ self.precision_matrix @ torch.tensor(self.preference_data, dtype=torch.float32)\n",
    "        predictive_variance = item_covariance - item_covariance @ self.precision_matrix @ item_covariance\n",
    "        \n",
    "        return predictive_mean, predictive_variance\n",
    "\n",
    "    def joint_predictive_mean_and_variance(self, f_hat, hessian, t_features, x_1_features, x_2_features):\n",
    "        k_t_star = torch.zeros(self.n_users, 1)\n",
    "        for i in range(self.n_users):\n",
    "            k_t_star[i] = self.se_kernel(t_features, self.user_features[i], self.sv_t, self.ls_t)\n",
    "        \n",
    "        k_x_star = torch.zeros(self.n_items, 2)\n",
    "        for i in range(self.n_items):\n",
    "            k_x_star[i, 0] = self.se_kernel(x_1_features, self.item_features[i], self.sv_k, self.ls_k)\n",
    "            k_x_star[i, 1] = self.se_kernel(x_2_features, self.item_features[i], self.sv_k, self.ls_k)\n",
    "        \n",
    "        kernel_t = self.kernel_covariance_matrix(t_features, t_features, self.sv_t, self.ls_t)\n",
    "        Sigma_star = torch.zeros(2, 2)\n",
    "        Sigma_star[0, 0] = kernel_t * self.kernel_covariance_matrix(x_1_features, x_1_features, self.sv_k, self.ls_k)\n",
    "        Sigma_star[1, 1] = kernel_t * self.kernel_covariance_matrix(x_2_features, x_2_features, self.sv_k, self.ls_k)\n",
    "        Sigma_star[0, 1] = kernel_t * self.kernel_covariance_matrix(x_1_features, x_2_features, self.sv_k, self.ls_k)\n",
    "        Sigma_star[1, 0] = kernel_t * self.kernel_covariance_matrix(x_2_features, x_1_features, self.sv_k, self.ls_k)\n",
    "        \n",
    "        k_star = torch.kron(k_t_star, k_x_star)\n",
    "        \n",
    "        predictive_mean = k_star.T @ self.precision_matrix @ f_hat\n",
    "        predictive_variance = Sigma_star - k_star.T @ torch.inverse(self.covariance_matrix + torch.inverse(hessian)) @ k_star\n",
    "        \n",
    "        return predictive_mean, predictive_variance\n",
    "    \n",
    "    def expected_improvement(self, t_features, x_features, f_hat, hessian, f_best=None):\n",
    "        if f_best is None:\n",
    "            f_best = torch.max(f_hat)\n",
    "        \n",
    "        predictive_mean, predictive_variance = self.predictive_mean_and_variance(f_hat, hessian, t_features, x_features)\n",
    "        \n",
    "        pred_sd = torch.sqrt(predictive_variance)\n",
    "        z_prime = (predictive_mean - f_best) / pred_sd\n",
    "        \n",
    "        return pred_sd * (z_prime * scipy.stats.norm.cdf(z_prime) + scipy.stats.norm.pdf(z_prime))\n",
    "    \n",
    "    def maximum_expected_improvement(self, t_features, item_features, f_hat, hessian, f_best=None):\n",
    "        maximum_ei = -np.inf\n",
    "        \n",
    "        for x in item_features:\n",
    "            ei = self.expected_improvement(t_features, x, f_hat, hessian, f_best)\n",
    "            if ei > maximum_ei:\n",
    "                maximum_ei = ei\n",
    "        \n",
    "        return maximum_ei\n",
    "    \n",
    "    def prob_i_over_j(self, t_features, x_1_index, x_2_index, f_hat, hessian):\n",
    "        predictive_mean, predictive_variance = self.joint_predictive_mean_and_variance(f_hat, hessian, t_features, self.item_features[x_1_index], self.item_features[x_2_index])\n",
    "        \n",
    "        numerator = predictive_mean[0] - predictive_mean[1]\n",
    "        denominator = predictive_variance[0, 0] - predictive_variance[1, 1] - 2 * predictive_variance[0, 1] - self.noise_sd ** 2\n",
    "        \n",
    "        return scipy.stats.norm.cdf(numerator / denominator)\n",
    "\n",
    "    def expected_value_of_information(self, t_index, x_1_index, x_2_index, f_hat, hessian, f_best=None):\n",
    "        t_features = self.user_features[t_index]\n",
    "        maximum_ei = self.maximum_expected_improvement(t_features, self.item_features, f_hat, hessian, f_best)\n",
    "        \n",
    "        preference_data_1_2 = self.preference_data + [[t_index, x_1_index, x_2_index]]\n",
    "        f_hat_1_2 = self.maximum_a_posteriori(f_hat, preference_data_1_2)\n",
    "        hessian_1_2 = self.hessian_log_p_D_given_f(f_hat_1_2, preference_data_1_2)\n",
    "        \n",
    "        preference_data_2_1 = self.preference_data + [[t_index, x_2_index, x_1_index]]\n",
    "        f_hat_2_1 = self.maximum_a_posteriori(f_hat, preference_data_2_1)\n",
    "        hessian_2_1 = self.hessian_log_p_D_given_f(f_hat_2_1, preference_data_2_1)\n",
    "        \n",
    "        mei_1_2 = self.maximum_expected_improvement(t_features, self.item_features, f_hat_1_2, hessian_1_2, f_best)\n",
    "        mei_2_1 = self.maximum_expected_improvement(t_features, self.item_features, f_hat_2_1, hessian_2_1, f_best)\n",
    "        \n",
    "        prob_1_2 = self.prob_i_over_j(t_features, x_1_index, x_2_index, f_hat, hessian)\n",
    "        prob_2_1 = 1 - prob_1_2\n",
    "        \n",
    "        return -maximum_ei + prob_1_2 * mei_1_2 + prob_2_1 * mei_2_1\n",
    "\n",
    "    def preference_elicitation(self, t_index, num_queries):\n",
    "        # Make a copy\n",
    "        pref_data = self.preference_data.copy()\n",
    "        f_hat = self.maximum_a_posteriori(np.zeros(self.n_users * self.n_items))\n",
    "        hessian = self.hessian_log_p_D_given_f(f_hat, pref_data)\n",
    "        pred_hist = []\n",
    "        \n",
    "        for i in range(num_queries):\n",
    "            max_evoi = -np.inf\n",
    "            for x_1 in range(self.n_items):\n",
    "                for x_2 in range(x_1 + 1, self.n_items):\n",
    "                    evoi = self.expected_value_of_information(t_index, x_1, x_2, f_hat, hessian)\n",
    "                    if evoi > max_evoi:\n",
    "                        max_evoi = evoi\n",
    "                        max_x_1 = x_1\n",
    "                        max_x_2 = x_2\n",
    "            \n",
    "            if get_preference(t_index, max_x_1, max_x_2):\n",
    "                pref_data.append([t_index, max_x_1, max_x_2])\n",
    "            else:\n",
    "                pref_data.append([t_index, max_x_2, max_x_1])\n",
    "            \n",
    "            f_hat = self.maximum_a_posteriori(f_hat, pref_data)\n",
    "            pred_hist.append(f_hat[t_index * self.n_items:(t_index + 1) * self.n_items])\n",
    "            hessian = self.hessian_log_p_D_given_f(f_hat, pref_data)\n",
    "        \n",
    "        return pred_hist\n",
    "\n",
    "# Example usage\n",
    "# model = GPPrefenceElicitation()\n",
    "# user_features = np.random.rand(50, 5)  # Replace with actual user features\n",
    "# item_features = np.random.rand(10, 5)  # Replace with actual item features\n",
    "# preference_data = np.array([[0, 1, 2], [1, 3, 4], [2, 5, 6]])  # Replace with actual preference data\n",
    "\n",
    "# model.fit(user_features, item_features, preference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\pedro\\Desktop\\GP-PreferenceElicitation\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_9128\\1168667401.py\", line 1, in <module>\n",
      "    user_features_v=torch.tensor(user_features.values, dtype=torch.float32)\n",
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_9128\\1168667401.py:1: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  user_features_v=torch.tensor(user_features.values, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "user_features_v=torch.tensor(user_features.values, dtype=torch.float32)\n",
    "item_features_v=torch.tensor(item_features.values, dtype=torch.float32)\n",
    "\n",
    "# model = GPPrefenceElicitation()\n",
    "# model.fit(user_features_v[:100], item_features_v, pairwise_df.values,max_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_9128\\3409976812.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=torch.float32)\n",
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_9128\\3409976812.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n",
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_9128\\3409976812.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=torch.float32)\n",
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_9128\\3409976812.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "\n",
    "# Substitua pelas suas variáveis reais\n",
    "# user_features_v = np.random.rand(50, 5)  # Exemplo de dados de características dos usuários\n",
    "# item_features_v = np.random.rand(10, 5)  # Exemplo de dados de características dos itens\n",
    "\n",
    "# # Exemplo de dados de preferências pareadas como DataFrame\n",
    "# pairwise_df = pd.DataFrame({\n",
    "#     'user_id': np.repeat(np.arange(50), 10),\n",
    "#     'item_1': np.tile(np.arange(10), 50),\n",
    "#     'item_2': np.tile((np.arange(10) + 1) % 10, 50)\n",
    "# })\n",
    "\n",
    "# Instancie seu modelo\n",
    "model = GPPrefenceElicitation()\n",
    "\n",
    "# Defina o número de divisões para a validação cruzada\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "# Lista para armazenar as perdas normalizadas para diferentes números de consultas\n",
    "all_normalized_losses = []\n",
    "\n",
    "prediction_histories = {}\n",
    "\n",
    "# Realize a validação cruzada\n",
    "for train_index, test_index in kf.split(pairwise_df['user_id'].unique()):\n",
    "    # Ajuste os índices para incluir todos os 10 pares de cada usuário\n",
    "    train_users = pairwise_df['user_id'].isin(train_index)\n",
    "    test_users = pairwise_df['user_id'].isin(test_index)\n",
    "\n",
    "    # Divida os dados em treino e teste\n",
    "    train_pairwise = pairwise_df[train_users].values\n",
    "    test_pairwise = pairwise_df[test_users].values\n",
    "    \n",
    "    # Ajuste o modelo aos dados de treino\n",
    "    model.fit(user_features_v, item_features_v, train_pairwise, max_iter=2)\n",
    "        \n",
    "    # Realize a elicitação para o conjunto de teste\n",
    "    for t_index in test_index:\n",
    "        prediction_histories[t_index] = model.preference_elicitation(t_index, num_queries=15)\n",
    "\n",
    "# # Combine e analise os resultados\n",
    "# all_normalized_losses = np.array(all_normalized_losses)\n",
    "# mean_losses = np.mean(all_normalized_losses, axis=0)\n",
    "# std_losses = np.std(all_normalized_losses, axis=0)\n",
    "\n",
    "# for i, num_queries in enumerate(query_counts):\n",
    "#     print(f\"Mean normalized loss for {num_queries} queries:\", mean_losses[i])\n",
    "#     print(f\"Standard deviation of normalized loss for {num_queries} queries:\", std_losses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
